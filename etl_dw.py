# -*- coding: utf-8 -*-
"""etl_dw.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AbRYvXFIhbj3Abnz_sJ-UKVPBI5NUhnL
"""

import pandas as pd
import numpy as np
import sqlite3 as sql
from datetime import datetime
from sqlite3 import IntegrityError
import gc
import itertools
import os
import pytz
import requests
import sys
import zipfile
brasil_tz = pytz.timezone('America/Sao_Paulo')

def baixar_arquivo_direto(url, nome_arquivo_local):
    """
    Baixa um arquivo direto (CSV, XLS) se não existir,
    usando headers para simular um navegador.
    """
    if os.path.exists(nome_arquivo_local):
        print(f"✓ Arquivo '{nome_arquivo_local}' já existe.")
        return True

    print(f"Baixando '{nome_arquivo_local}' da fonte oficial...")

    # Headers para evitar erros 403 (Proibido) em alguns sites .gov
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        with requests.get(url, stream=True, headers=headers) as r:
            r.raise_for_status()
            with open(nome_arquivo_local, 'wb') as f:
                for data in r.iter_content(8192):
                    f.write(data)
        print(f"✓ Download de '{nome_arquivo_local}' concluído.")
        return True
    except requests.exceptions.RequestException as e:
        print(f"\nERRO: Falha ao baixar o arquivo direto: {e}")
        if os.path.exists(nome_arquivo_local):
            os.remove(nome_arquivo_local)
        return False

def baixar_e_extrair_zip(url, nome_arquivo_no_zip, nome_arquivo_local):
    """
    Baixa um arquivo .zip em memória, extrai um arquivo específico
    de dentro dele e o salva localmente com o nome desejado.
    """
    if os.path.exists(nome_arquivo_local):
        print(f"✓ Arquivo '{nome_arquivo_local}' já existe (extraído anteriormente).")
        return True

    print(f"Baixando e extraindo '{nome_arquivo_local}' da fonte oficial (ZIP)...")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        # 1. Baixa o arquivo ZIP em memória
        r = requests.get(url, headers=headers)
        r.raise_for_status()

        # 2. Abre o ZIP a partir da memória
        with io.BytesIO(r.content) as buffer_memoria:
            with zipfile.ZipFile(buffer_memoria, 'r') as z:
                # 3. Extrai o arquivo específico do ZIP para o disco
                with z.open(nome_arquivo_no_zip) as zf:
                    # 4. Salva com o nome local que o script espera
                    with open(nome_arquivo_local, 'wb') as f:
                        f.write(zf.read())

        print(f"✓ Arquivo '{nome_arquivo_local}' extraído com sucesso.")
        return True
    except requests.exceptions.RequestException as e:
        print(f"\nERRO: Falha ao baixar o ZIP de {url}: {e}")
        return False
    except KeyError:
        print(f"\nERRO: Arquivo '{nome_arquivo_no_zip}' não encontrado dentro do ZIP baixado de {url}.")
        print("Verifique se o nome do arquivo dentro do ZIP mudou no site oficial.")
        return False
    except zipfile.BadZipFile:
        print(f"\nERRO: O arquivo baixado de {url} não é um ZIP válido.")
        return False
    except Exception as e:
        print(f"\nERRO inesperado ao processar o ZIP: {e}")
        return False

def baixar_dados_mortalidade(ano):
    """
    Verifica se o arquivo CSV de mortalidade de um ano específico existe localmente.
    Se não existir, faz o download da fonte oficial do OPENDATASUS.
    """

    # O script usa este nome localmente
    nome_arquivo_local = f"Mortalidade_Geral_{ano}.csv"

    # 1. Verifica se o arquivo já existe localmente
    if os.path.exists(nome_arquivo_local):
        print(f"[{ano}] Arquivo {nome_arquivo_local} já existe localmente. Download pulado.")
        return True

    # 2. Se não existir, define a URL oficial do OpenDataSUS
    print(f"[{ano}] Arquivo {nome_arquivo_local} não encontrado. Iniciando download da fonte oficial...")

    # Padrão de URL do OpenDataSUS (ex: 2023 -> '23')
    ano_curto = str(ano)[2:]
    nome_arquivo_remoto = f"DO{ano_curto}OPEN.csv"

    url_base = "https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SIM/"
    url = f"{url_base}{nome_arquivo_remoto}"

    try:
        # 3. Faz o download (stream=True é bom para arquivos grandes)
        with requests.get(url, stream=True) as r:
            r.raise_for_status() # Lança um erro se a URL estiver quebrada (404, 500)

            # Pega o tamanho total do arquivo (para barra de progresso)
            total_size = int(r.headers.get('content-length', 0))
            bloco_size = 8192 # 8KB

            # Salva o arquivo com o NOME LOCAL esperado pelo script
            with open(nome_arquivo_local, 'wb') as f:
                # Barra de progresso simples
                for i, data in enumerate(r.iter_content(bloco_size)):
                    f.write(data)
                    # Imprime o progresso a cada 100 blocos
                    if i % 100 == 0:
                        baixado = i * bloco_size
                        if total_size > 0:
                            percent = (baixado / total_size) * 100
                            sys.stdout.write(f"\r[{ano}] Baixando {nome_arquivo_remoto}... {percent:.1f}% ({baixado/1024/1024:.1f} MB)")
                        else:
                            sys.stdout.write(f"\r[{ano}] Baixando {nome_arquivo_remoto}... ({baixado/1024/1024:.1f} MB)")

            sys.stdout.write(f"\r[{ano}] Download de {nome_arquivo_remoto} concluído. Salvo como {nome_arquivo_local}. \n")
        return True

    except requests.exceptions.RequestException as e:
        print(f"\nERRO: Falha ao baixar o arquivo de {ano} da URL oficial: {url}")
        print(f"Detalhe: {e}")
        # Se o arquivo não existir na fonte (ex: 2024 pode não estar como DO24OPEN.csv ainda)
        if "404 Client Error" in str(e) or "403 Client Error" in str(e):
             print(f"[{ano}] Aviso: O arquivo {nome_arquivo_remoto} pode ainda não estar disponível no OpenDataSUS. Pulando este ano.")
             return False
        return False
    except Exception as e:
        print(f"\nERRO inesperado durante o download de {ano}: {e}")
        return False

def valor_padrao(valor, padrao=-1):
    if pd.isna(valor) or str(valor).strip() == "":
        return padrao
    return valor

def criar_sexo(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_SEXO""")
  cursor.execute("""
  INSERT INTO DWCD_SEXO VALUES
  (-1, '-1', 'Inválido', ?),
  (1, '1', 'Masculino', ?),
  (2, 'M', 'Masculino', ?),
  (3, '2', 'Feminino', ?),
  (4, 'F', 'Feminino', ?),
  (5, 'I', 'Ignorado', ?),
  (6, '0', 'Ignorado', ?),
  (7, '9', 'Ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora, agora, agora))

def criar_raca(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_RACA""")
  cursor.execute("""
  INSERT INTO DWCD_RACA VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'Branca', ?),
  (2, 2, 'Preta', ?),
  (3, 3, 'Amarela', ?),
  (4, 4, 'Parda', ?),
  (5, 5, 'Indígena', ?)
  """, (agora, agora, agora, agora, agora, agora))

def criar_obito_puerperio(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_OBITO_PUERPERIO""")
  cursor.execute("""
  INSERT INTO DWCD_OBITO_PUERPERIO
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'Sim, até 42 dias após o parto', ?),
  (2, 2, 'Sim, de 43 dias a 1 ano', ?),
  (3, 3, 'Não', ?),
  (4, 9, 'Ignorado', ?)
  """, (agora, agora, agora, agora, agora))

def criar_ocorrencia_obito(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_OCORRENCIA_OBITO""")
  cursor.execute("""
  INSERT INTO DWCD_OCORRENCIA_OBITO
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'Na gravidez', ?),
  (2, 2, 'No parto', ?),
  (3, 3, 'No abortamento', ?),
  (4, 4, 'Até 42 dias após o término do parto', ?),
  (5, 5, 'De 43 dias a 1 ano após o término da gestação', ?),
  (6, 8, 'Não ocorreu nestes períodos', ?),
  (7, 9, 'Ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora, agora, agora))

def criar_fonte_informacoes(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_FONTE_INFORMACAO""")
  cursor.execute("""
  INSERT INTO DWCD_FONTE_INFORMACAO
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'ocorrência policial', ?),
  (2, 2, 'hospital', ?),
  (3, 3, 'família', ?),
  (4, 4, 'outra', ?),
  (5, 9, 'ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora))

def criar_local_tipo_ocorrencia(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_LOCAL_TIPO_OCORRENCIA""")
  cursor.execute("""
  INSERT INTO DWCD_LOCAL_TIPO_OCORRENCIA
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'via pública', ?),
  (2, 2, 'endereço de residência', ?),
  (3, 3, 'outro domicílio', ?),
  (4, 4, 'estabelecimento comercial', ?),
  (5, 5, 'outros', ?),
  (6, 9, 'ignorada', ?)
  """, (agora, agora, agora, agora, agora, agora, agora))

def criar_metodo_parto(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_METODO_PARTO""")
  cursor.execute("""
  INSERT INTO DWCD_METODO_PARTO
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'vaginal', ?),
  (2, 2, 'cesáreo', ?),
  (3, 9, 'ignorado', ?)
  """, (agora, agora, agora, agora))

def criar_escolaridade(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_ESCOLARIDADE""")
  cursor.execute("""
  INSERT INTO DWCD_ESCOLARIDADE
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 0, 'Sem escolaridade', ?),
  (2, 1, 'Fundamental I (1ª a 4ª série)', ?),
  (3, 2, 'Fundamental II (5ª a 8ª série)', ?),
  (4, 3, 'Médio (antigo 2º Grau)', ?),
  (5, 4, 'Superior incompleto', ?),
  (6, 5, 'Superior completo', ?),
  (7, 9, 'Ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora, agora, agora))

def criar_local_ocorrencia(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_LOCAL_OCORRENCIA""")
  cursor.execute("""
  INSERT INTO DWCD_LOCAL_OCORRENCIA
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'hospital', ?),
  (2, 2, 'outros estabelecimentos de saúde', ?),
  (3, 3, 'domicílio', ?),
  (4, 4, 'via pública', ?),
  (5, 5, 'outros', ?),
  (6, 6, 'aldeia indígena', ?),
  (7, 9, 'ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora, agora, agora))

def criar_estado_civil(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_ESTADO_CIVIL""")
  cursor.execute("""
  INSERT INTO DWCD_ESTADO_CIVIL
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'Solteiro', ?),
  (2, 2, 'Casado', ?),
  (3, 3, 'Viúvo', ?),
  (4, 4, 'Separado judicialmente/divorciado', ?),
  (5, 5, 'União estável', ?),
  (6, 9, 'Ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora, agora))

def criar_circunstancia_obito(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_CIRCUNSTANCIA_OBITO""")
  cursor.execute("""
  INSERT INTO DWCD_CIRCUNSTANCIA_OBITO
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'acidente', ?),
  (2, 2, 'suicídio', ?),
  (3, 3, 'homicídio', ?),
  (4, 4, 'outros', ?) ,
  (5, 9, 'ignorado', ?)
  """, (agora, agora, agora, agora, agora, agora))

def criar_tipo_gravidez(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_GESTACAO_MULTIPLA""")
  cursor.execute("""
  INSERT INTO DWCD_GESTACAO_MULTIPLA
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'única', ?),
  (2, 2, 'dupla', ?),
  (3, 3, 'tripla e mais', ?),
  (4, 9, 'ignorado', ?)
  """, (agora, agora, agora, agora, agora))

def limpar_pessoa_obito(cursor):
  cursor.execute("""DELETE FROM DWMV_OBITO""")
  cursor.execute("""DELETE FROM DWCD_PESSOA""")

def criar_pessoa_obito(cursor, caminho, ano):
    batch_size = 32677

    cursor.execute("SELECT SK_Dados_Demograficos FROM DWMV_Obito WHERE DT_Data LIKE ?", ('%' + str(ano),))
    sks_demograficos = cursor.fetchall()

    if sks_demograficos:
        lista_sks = [sk[0] for sk in sks_demograficos]
        cursor.execute("DELETE FROM DWMV_Obito WHERE DT_Data LIKE ?", ('%' + str(ano),))
        print(f"Deleted {len(lista_sks)} records from DWMV_Obito.")

        for i in range(0, len(lista_sks), batch_size):
            batch = lista_sks[i:i + batch_size]
            placeholders = ', '.join(['?'] * len(batch))
            cursor.execute(f"DELETE FROM DWCD_DADOS_DEMOGRAFICOS WHERE SK_Dados_Demograficos IN ({placeholders})", batch)
    else:
        print("No records found for the specified year.")

    df_cru = pd.read_csv(caminho, sep=';', quotechar='"', dtype=str, encoding='ISO-8859-1')
    df_cru['LINHAA'] = df_cru['LINHAA'].str.replace(r"\*|X$", "", regex=True)
    df_cru['HORAOBITO'] = df_cru['HORAOBITO'].astype(str).str.strip().replace({'nan': None})

    dt_times = pd.to_datetime(df_cru['HORAOBITO'], format='%H%M', errors='coerce')

    df_cru['HORAOBITO'] = dt_times.dt.strftime('%H:%M:%S')
    df_cru['HORAOBITO'] = df_cru['HORAOBITO'].where(df_cru['HORAOBITO'].notna(), None)

    df_cru['HORA'] = dt_times.dt.hour
    df_cru['HORA'] = df_cru['HORA'].where(df_cru['HORA'].notna(), None)
    df_cru = df_cru.replace("", -1).fillna(-1)
    df_cru['IDADE'] = pd.to_numeric(df_cru['IDADE'], errors='coerce')

    # Regra 1: Trata idades no formato SIM (4xx = xx anos)
    # Ex: 450 vira 50
    df_cru.loc[(df_cru['IDADE'] >= 400) & (df_cru['IDADE'] <= 599), 'IDADE'] = df_cru['IDADE'] - 400

    # Regra 2: Trata códigos de 'ignorado' (ex: 999) como -1
    df_cru.loc[df_cru['IDADE'] > 900, 'IDADE'] = -1

    # Regra 3: Trata idades impossíveis (ex: > 125) como -1
    df_cru.loc[df_cru['IDADE'] > 125, 'IDADE'] = -1
    agora = datetime.now(brasil_tz)
    agora = agora.strftime('%Y-%m-%d %H:%M:%S')

    nm_arquivo = os.path.basename(caminho)

    sexo_map = dict(cursor.execute("SELECT CAST(CD_Sexo AS TEXT), SK_Sexo FROM DWCD_SEXO").fetchall())
    raca_map = dict(cursor.execute("SELECT CAST(CD_Raca AS TEXT), SK_Raca FROM DWCD_RACA").fetchall())
    ocupacao_map = dict(cursor.execute("SELECT CAST(CD_Ocupacao AS TEXT), SK_Ocupacao FROM DWCD_OCUPACAO").fetchall())
    estado_civil_map = dict(cursor.execute("SELECT CAST(CD_Estado_Civil AS TEXT), SK_Estado_Civil FROM DWCD_ESTADO_CIVIL").fetchall())
    escolaridade_map = dict(cursor.execute("SELECT CAST(CD_Escolaridade AS TEXT), SK_Escolaridade FROM DWCD_ESCOLARIDADE").fetchall())
    municipio_map = dict(cursor.execute("SELECT CAST(CD_Municipio AS TEXT), SK_Municipio FROM DWCD_MUNICIPIO").fetchall())
    local_ocorrencia_map = dict(cursor.execute("SELECT CAST(CD_Local_Ocorrencia AS TEXT), SK_Local_Ocorrencia FROM DWCD_LOCAL_OCORRENCIA").fetchall())
    escolaridade_mae_map = escolaridade_map
    gestacao_multipla_map = dict(cursor.execute("SELECT CAST(CD_Gestacao_Multipla AS TEXT), SK_Gestacao_Multipla FROM DWCD_GESTACAO_MULTIPLA").fetchall())
    metodo_parto_map = dict(cursor.execute("SELECT CAST(CD_Metodo_Parto AS TEXT), SK_Metodo_Parto FROM DWCD_METODO_PARTO").fetchall())
    obito_parto_map = dict(cursor.execute("SELECT CAST(CD_Obito_Parto AS TEXT), SK_Obito_Parto FROM DWCD_OBITO_PARTO").fetchall())
    ocorrencia_obito_map = dict(cursor.execute("SELECT CAST(CD_Ocorrencia_Obito AS TEXT), SK_Ocorrencia_Obito FROM DWCD_OCORRENCIA_OBITO").fetchall())
    circunstancia_obito_map = dict(cursor.execute("SELECT CAST(CD_Circunstancia_Obito AS TEXT), SK_Circunstancia_Obito FROM DWCD_CIRCUNSTANCIA_OBITO").fetchall())
    fonte_informacao_map = dict(cursor.execute("SELECT CAST(CD_Fonte_Informacao AS TEXT), SK_Fonte_Informacao FROM DWCD_FONTE_INFORMACAO").fetchall())
    local_tipo_ocorrencia_map = dict(cursor.execute("SELECT CAST(CD_Local_Tipo_Ocorrencia AS TEXT), SK_Local_Tipo_Ocorrencia FROM DWCD_LOCAL_TIPO_OCORRENCIA").fetchall())
    obito_puerperio_map = dict(cursor.execute("SELECT CAST(CD_Obito_Puerperio AS TEXT), SK_Obito_Puerperio FROM DWCD_OBITO_PUERPERIO").fetchall())
    cid_map = dict(cursor.execute("SELECT CAST(CD_CID AS TEXT), SK_CID FROM DWCD_CID").fetchall())

    cursor.execute("SELECT COALESCE(MAX(SK_Dados_Demograficos), 0) FROM DWCD_DADOS_DEMOGRAFICOS")
    last_sk = cursor.fetchone()[0]
    sk_generator = itertools.count(last_sk + 1)

    dados_pessoa_batch = []
    dados_obito_batch = []

    for linha in df_cru.itertuples(index=False):
        sk_novo = next(sk_generator)

        sexo_sk = sexo_map.get(linha.SEXO, -1)
        raca_sk = raca_map.get(linha.RACACOR, -1)
        estado_civil_sk = estado_civil_map.get(linha.ESTCIV, -1)
        escolaridade_sk = escolaridade_map.get(linha.ESC, -1)
        municipio_residencia_sk = municipio_map.get(linha.CODMUNRES, -1)
        ocupacao_sk = ocupacao_map.get(linha.OCUP, -1)

        dados_pessoa_batch.append((
            sk_novo,
            nm_arquivo,
            sexo_sk,
            municipio_residencia_sk,
            raca_sk,
            estado_civil_sk,
            escolaridade_sk,
            ocupacao_sk,
            linha.NATURAL,
            linha.IDADE,
            linha.DTNASC,
            agora
        ))

        local_ocorrencia_sk = local_ocorrencia_map.get(linha.LOCOCOR, -1)
        municipio_ocorrencia_sk = municipio_map.get(linha.CODMUNOCOR, -1)
        escolaridade_mae_sk = escolaridade_mae_map.get(linha.ESCMAE2010, -1)
        gestacao_multipla_sk = gestacao_multipla_map.get(linha.GRAVIDEZ, -1)
        metodo_parto_sk = metodo_parto_map.get(linha.PARTO, -1)
        obito_parto_sk = obito_parto_map.get(linha.OBITOPARTO, -1)
        ocorrencia_obito_sk = ocorrencia_obito_map.get(linha.TPMORTEOCO, -1)
        circunstancia_obito_sk = circunstancia_obito_map.get(linha.CIRCOBITO, -1)
        fonte_informacao_sk = fonte_informacao_map.get(linha.FONTE, -1)
        local_tipo_ocorrencia_sk = local_tipo_ocorrencia_map.get(linha.TPOBITOCOR, -1)
        obito_puerperio_sk = obito_puerperio_map.get(linha.OBITOPUERP, -1)
        cid_sk = cid_map.get(linha.LINHAA, -1)
        ocupacao_mae_sk = ocupacao_map.get(linha.OCUPMAE, -1)
        causa_basica_sk = cid_map.get(linha.CAUSABAS, -1)

        dados_obito_batch.append((
            sk_novo,
            linha.TIPOBITO,
            linha.DTOBITO,
            linha.HORA,
            linha.HORAOBITO,
            local_ocorrencia_sk,
            municipio_ocorrencia_sk,
            linha.CODESTAB,
            linha.IDADEMAE,
            escolaridade_mae_sk,
            ocupacao_mae_sk,
            linha.QTDFILVIVO,
            linha.QTDFILMORT,
            linha.SEMAGESTAC,
            gestacao_multipla_sk,
            metodo_parto_sk,
            obito_parto_sk,
            linha.PESO,
            ocorrencia_obito_sk,
            linha.ASSISTMED,
            linha.NECROPSIA,
            cid_sk,
            causa_basica_sk,
            linha.ATESTANTE,
            linha.COMUNSVOIM,
            linha.DTATESTADO,
            circunstancia_obito_sk,
            linha.ACIDTRAB,
            fonte_informacao_sk,
            local_tipo_ocorrencia_sk,
            obito_puerperio_sk,
            linha.EXAME,
            linha.CIRURGIA,
            agora
        ))


    cursor.executemany("""
        INSERT INTO DWCD_DADOS_DEMOGRAFICOS (
            SK_Dados_Demograficos, NM_Arquivo, SK_Sexo, SK_Municipio_Residencia,
            SK_Raca, SK_Estado_Civil, SK_Escolaridade, SK_Ocupacao, SK_Naturalidade,
            DS_Idade, DT_Nascimento, DT_Carga
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, dados_pessoa_batch)

    cursor.executemany("""
        INSERT INTO DWMV_OBITO (
            SK_Dados_Demograficos, ST_Obito_Fetal, DT_Data, DT_Hora, DT_Hora_Minuto, SK_Local_Ocorrencia, SK_Municipio,
            DS_Estabelecimento, DS_Idade_Mae, SK_Escolaridade_Mae, SK_Ocupacao_Mae, DS_Filhos_Vivos,
            DS_Filhos_Perdidos, DS_Semanas_Gestacao, SK_Gestacao_Multipla, SK_Metodo_Parto, SK_Obito_Parto,
            DS_Peso_Nascimento, SK_Ocorrencia_Obito, ST_Assistencia_Medica, ST_Necropsia, SK_CID,
            SK_Causa_Basica, DS_Atestado_Medico, DS_Municipio_SVO_IML, DT_Atestado, SK_Circunstancia_Obito,
            ST_Acidente_Trabalho, SK_Fonte_Informacao, SK_Local_Tipo_Ocorrencia_Acidente, SK_Obito_Puerperio,
            ST_Exame, ST_Cirurgia, DT_Carga
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, dados_obito_batch)

    del df_cru, dados_pessoa_batch, dados_obito_batch
    gc.collect()

def criar_municipios(cursor, caminho):
    agora = datetime.now(brasil_tz).strftime('%Y-%m-%d %H:%M:%S')

    df_cru = pd.read_excel(caminho, skiprows=6, header=None)
    df_cru.columns = df_cru.iloc[0]
    df_municipio = df_cru[1:].reset_index(drop=True)

    cursor.execute("""
    INSERT INTO DWCD_MUNICIPIO (SK_Municipio, CD_Municipio, NM_Municipio, SK_UF, DT_Carga)
    VALUES (?, ?, ?, ?, ?)
    ON CONFLICT(CD_Municipio) DO NOTHING
    """, (-1, -1, "Inválido", -1, agora))

    UF_map = dict(cursor.execute("SELECT CAST(\"CD_UF\" AS TEXT), SK_UF FROM DWCD_UF").fetchall())

    for _, row in df_municipio.iterrows():
        codigo_ibge = int(row['Código Município Completo'])  # 7 dígitos
        codigo_base = codigo_ibge // 10  # remove dígito verificador
        UF_sk = UF_map.get(row['UF'], -1)

        cursor.execute("""
        INSERT INTO DWCD_MUNICIPIO (CD_Municipio, NM_Municipio, SK_UF, DT_Carga)
        VALUES (?, ?, ?, ?)
        ON CONFLICT(CD_Municipio)
        DO UPDATE SET
            NM_Municipio = excluded.NM_Municipio,
            SK_UF = excluded.SK_UF,
            DT_Carga = excluded.DT_Carga
        """, (codigo_base, row['Nome_Município'], UF_sk, agora))

def criar_obito_parto(cursor):
  agora = datetime.now(brasil_tz)
  agora = agora.strftime('%Y-%m-%d %H:%M:%S')
  cursor.execute("""DELETE FROM DWCD_OBITO_PARTO""")
  cursor.execute("""
  INSERT INTO DWCD_OBITO_PARTO
  VALUES
  (-1, -1, 'Inválido', ?),
  (1, 1, 'antes', ?),
  (2, 2, 'durante', ?),
  (3, 3, 'depois', ?),
  (4, 9, 'Ignorado', ?)
  """, (agora, agora, agora, agora, agora))

def criar_cid(cursor, caminho):
    agora = datetime.now(brasil_tz).strftime('%Y-%m-%d %H:%M:%S')
    df_raw = pd.read_csv(caminho, sep=';', encoding='ISO-8859-1')
    cursor.execute("""
    INSERT INTO DWCD_CID (SK_CID, CD_CID, DS_CID, DT_Carga)
    VALUES (?, ?, ?, ?)
    ON CONFLICT(CD_CID) DO NOTHING
    """, (-1, -1, "Inválido", agora))

    for _, row in df_raw.iterrows():
        cursor.execute("""
        INSERT INTO DWCD_CID (CD_CID, DS_CID, DT_Carga)
        VALUES (?, ?, ?)
        ON CONFLICT(CD_CID)
        DO UPDATE SET
            DS_CID = excluded.DS_CID,
            DT_Carga = excluded.DT_Carga
        """, (row.get('SUBCAT'), row.get('DESCRICAO'), agora))

def criar_uf(cursor, caminho):
    agora = datetime.now(brasil_tz).strftime('%Y-%m-%d %H:%M:%S')
    df_cru = pd.read_excel(caminho, skiprows=6, header=None)
    df_cru.columns = df_cru.iloc[0]
    df_municipio = df_cru[1:].reset_index(drop=True)
    df_uf_cru = df_municipio[['UF', 'Nome_UF']]
    df_uf = df_uf_cru.drop_duplicates()
    cursor.execute("""
    INSERT INTO DWCD_UF (SK_UF, CD_UF, NM_UF, DT_Carga)
    VALUES (?, ?, ?, ?)
    ON CONFLICT(CD_UF) DO NOTHING
    """, (-1, -1, "Inválido", agora))

    for _, row in df_uf.iterrows():
        cursor.execute("""
        INSERT INTO DWCD_UF (CD_UF, NM_UF, DT_Carga)
        VALUES (?, ?, ?)
        ON CONFLICT(CD_UF)
        DO UPDATE SET
            NM_UF = excluded.NM_UF,
            DT_Carga = excluded.DT_Carga
        """, (row['UF'], row['Nome_UF'], agora))

def criar_ocupacao(cursor, caminho):
    agora = datetime.now(brasil_tz).strftime('%Y-%m-%d %H:%M:%S')
    df = pd.read_csv(caminho, sep=';', quotechar='"', encoding='ISO-8859-1')
    cursor.execute("""
    INSERT INTO DWCD_OCUPACAO (SK_Ocupacao, CD_Ocupacao, DS_Ocupacao, DT_Carga)
    VALUES (?, ?, ?, ?)
    ON CONFLICT(CD_Ocupacao) DO NOTHING
    """, (-1, -1, "Inválido", agora))

    for _, row in df.iterrows():
        cursor.execute("""
        INSERT INTO DWCD_OCUPACAO (CD_Ocupacao, DS_Ocupacao, DT_Carga)
        VALUES (?, ?, ?)
        ON CONFLICT(CD_Ocupacao)
        DO UPDATE SET
            DS_Ocupacao = excluded.DS_Ocupacao,
            DT_Carga = excluded.DT_Carga
        """, (row['CODIGO'], row['TITULO'], agora))

def criar_base_de_dados(cursor):
  cursor.executescript("""
CREATE TABLE IF NOT EXISTS "DWCD_OCUPACAO" (
	"SK_Ocupacao" INTEGER NOT NULL,
	"CD_Ocupacao" INTEGER NOT NULL UNIQUE,
	"DS_Ocupacao" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Ocupacao")
);

CREATE TABLE IF NOT EXISTS "DWCD_UF" (
	"SK_UF" INTEGER NOT NULL,
	"CD_UF" INTEGER NOT NULL UNIQUE,
	"NM_UF" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_UF")
);

CREATE TABLE IF NOT EXISTS "DWCD_OBITO_PARTO" (
	"SK_Obito_Parto" INTEGER NOT NULL,
	"CD_Obito_Parto" INTEGER NOT NULL UNIQUE,
	"DS_Obito_Parto" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Obito_Parto")
);

CREATE TABLE IF NOT EXISTS "DWCD_CID" (
	"SK_CID" INTEGER NOT NULL,
	"CD_CID" VARCHAR NOT NULL UNIQUE,
	"DS_CID" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_CID")
);

CREATE TABLE IF NOT EXISTS "DWCD_DADOS_DEMOGRAFICOS" (
	"SK_Dados_Demograficos" INTEGER NOT NULL,
	"NM_Arquivo" VARCHAR NOT NULL,
	"SK_Sexo" INTEGER NOT NULL,
	"SK_Municipio_Residencia" INTEGER NOT NULL,
	"SK_Raca" INTEGER,
	"SK_Estado_Civil" INTEGER,
	"SK_Escolaridade" INTEGER,
	"SK_Ocupacao" INTEGER,
	"SK_Naturalidade" INTEGER,
	"DS_Idade" INTEGER,
	"DT_Nascimento" DATE,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Dados_Demograficos", "NM_Arquivo", "SK_Sexo", "SK_Municipio_Residencia"),
	FOREIGN KEY ("SK_Estado_Civil") REFERENCES "DWCD_ESTADO_CIVIL"("SK_Estado_Civil")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Raca") REFERENCES "DWCD_RACA"("SK_Raca")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Sexo") REFERENCES "DWCD_SEXO"("SK_Sexo")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Municipio_Residencia") REFERENCES "DWCD_MUNICIPIO"("SK_Municipio")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Naturalidade") REFERENCES "DWCD_MUNICIPIO"("SK_Municipio")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Escolaridade") REFERENCES "DWCD_ESCOLARIDADE"("SK_Escolaridade")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Ocupacao") REFERENCES "DWCD_OCUPACAO"("SK_Ocupacao")
	ON UPDATE NO ACTION ON DELETE NO ACTION
);

CREATE TABLE IF NOT EXISTS "DWMV_OBITO" (
	"SK_Dados_Demograficos" INTEGER NOT NULL UNIQUE,
	"SK_CID" INTEGER NOT NULL,
	"SK_Municipio" INTEGER NOT NULL,
	"SK_Local_Ocorrencia" INTEGER NOT NULL,
	"ST_Obito_Fetal" INTEGER NOT NULL,
	"DT_Data" DATE NOT NULL,
	"SK_Obito_Parto" INTEGER,
	"SK_Causa_Basica" INTEGER,
	"SK_Escolaridade_Mae" INTEGER,
	"SK_Ocupacao_Mae" INTEGER,
	"SK_Gestacao_Multipla" INTEGER,
	"SK_Metodo_Parto" INTEGER,
	"SK_Ocorrencia_Obito" INTEGER,
	"SK_Circunstancia_Obito" INTEGER,
	"SK_Local_Tipo_Ocorrencia_Acidente" INTEGER,
	"SK_Fonte_Informacao" INTEGER,
	"SK_Obito_Puerperio" INTEGER,
	"DT_Hora_Minuto" TIME,
	"DT_Hora" INTEGER,
	"DS_Estabelecimento" INTEGER,
	"DS_Idade_Mae" INTEGER,
	"DS_Filhos_Vivos" INTEGER,
	"DS_Filhos_Perdidos" INTEGER,
	"DS_Semanas_Gestacao" INTEGER,
	"DS_Peso_Nascimento" INTEGER,
	"DS_Atestado_Medico" INTEGER,
	"DS_Municipio_SVO_IML" INTEGER,
	"DT_Atestado" DATE,
	"ST_Necropsia" INTEGER,
	"ST_Acidente_Trabalho" INTEGER,
	"ST_Assistencia_Medica" INTEGER,
	"ST_Exame" INTEGER,
	"ST_Cirurgia" INTEGER,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Dados_Demograficos", "SK_CID", "SK_Municipio", "SK_Local_Ocorrencia", "ST_Obito_Fetal", "DT_Data"),
	FOREIGN KEY ("SK_Local_Ocorrencia") REFERENCES "DWCD_LOCAL_OCORRENCIA"("SK_Local_Ocorrencia")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Municipio") REFERENCES "DWCD_MUNICIPIO"("SK_Municipio")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Escolaridade_Mae") REFERENCES "DWCD_ESCOLARIDADE"("SK_Escolaridade")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Obito_Puerperio") REFERENCES "DWCD_OBITO_PUERPERIO"("SK_Obito_Puerperio")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Causa_Basica") REFERENCES "DWCD_CID"("SK_CID")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_CID") REFERENCES "DWCD_CID"("SK_CID")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Obito_Parto") REFERENCES "DWCD_OBITO_PARTO"("SK_Obito_Parto")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Local_Tipo_Ocorrencia_Acidente") REFERENCES "DWCD_LOCAL_TIPO_OCORRENCIA"("SK_Local_Tipo_Ocorrencia")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Fonte_Informacao") REFERENCES "DWCD_FONTE_INFORMACAO"("SK_Fonte_Informacao")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Circunstancia_Obito") REFERENCES "DWCD_CIRCUSTANCIA_OBITO"("SK_Circunstancia_Obito")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Ocorrencia_Obito") REFERENCES "DWCD_OCORRENCIA_OBITO"("SK_Ocorrencia_Obito")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Metodo_Parto") REFERENCES "DWCD_METODO_PARTO"("SK_Metodo_Parto")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Gestacao_Multipla") REFERENCES "DWCD_GESTACAO_MULTIPLA"("SK_Gestacao_Multipla")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Ocupacao_Mae") REFERENCES "DWCD_OCUPACAO"("SK_Ocupacao")
	ON UPDATE NO ACTION ON DELETE NO ACTION,
	FOREIGN KEY ("SK_Dados_Demograficos") REFERENCES "DWCD_DADOS_DEMOGRAFICOS"("SK_Dados_Demograficos")
	ON UPDATE NO ACTION ON DELETE NO ACTION
);

CREATE TABLE IF NOT EXISTS "DWCD_GESTACAO_MULTIPLA" (
	"SK_Gestacao_Multipla" INTEGER NOT NULL,
	"CD_Gestacao_Multipla" INTEGER NOT NULL UNIQUE,
	"DS_Gestacao_Multipla" VARCHAR NOT NULL UNIQUE,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Gestacao_Multipla")
);

CREATE TABLE IF NOT EXISTS "DWCD_MUNICIPIO" (
	"SK_Municipio" INTEGER NOT NULL,
	"CD_Municipio" INTEGER NOT NULL UNIQUE,
	"NM_Municipio" VARCHAR NOT NULL,
	"SK_UF" INTEGER NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Municipio"),
	FOREIGN KEY ("SK_UF") REFERENCES "DWCD_UF"("SK_UF")
	ON UPDATE NO ACTION ON DELETE NO ACTION
);

CREATE TABLE IF NOT EXISTS "DWCD_ESTADO_CIVIL" (
	"SK_Estado_Civil" INTEGER NOT NULL,
	"CD_Estado_Civil" INTEGER NOT NULL UNIQUE,
	"DS_Estado_Civil" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Estado_Civil")
);

CREATE TABLE IF NOT EXISTS "DWCD_LOCAL_OCORRENCIA" (
	"SK_Local_Ocorrencia" INTEGER NOT NULL,
	"CD_Local_Ocorrencia" INTEGER NOT NULL UNIQUE,
	"DS_Local_Ocorrencia" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Local_Ocorrencia")
);

CREATE TABLE IF NOT EXISTS "DWCD_ESCOLARIDADE" (
	"SK_Escolaridade" INTEGER NOT NULL,
	"CD_Escolaridade" INTEGER NOT NULL UNIQUE,
	"DS_Escolaridade" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Escolaridade")
);

CREATE TABLE IF NOT EXISTS "DWCD_METODO_PARTO" (
	"SK_Metodo_Parto" INTEGER NOT NULL,
	"CD_Metodo_Parto" INTEGER NOT NULL UNIQUE,
	"DS_Metodo_Parto" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Metodo_Parto")
);

CREATE TABLE IF NOT EXISTS "DWCD_OCORRENCIA_OBITO" (
	"SK_Ocorrencia_Obito" INTEGER NOT NULL,
	"CD_Ocorrencia_Obito" INTEGER NOT NULL UNIQUE,
	"DS_Ocorrencia_Obito" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Ocorrencia_Obito")
);

CREATE TABLE IF NOT EXISTS "DWCD_CIRCUNSTANCIA_OBITO" (
	"SK_Circunstancia_Obito" INTEGER NOT NULL,
	"CD_Circunstancia_Obito" INTEGER NOT NULL UNIQUE,
	"DS_Circunstancia_Obito" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Circunstancia_Obito")
);

CREATE TABLE IF NOT EXISTS "DWCD_FONTE_INFORMACAO" (
	"SK_Fonte_Informacao" INTEGER NOT NULL,
	"CD_Fonte_Informacao" INTEGER NOT NULL UNIQUE,
	"DS_Fonte_Informacao" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Fonte_Informacao")
);

CREATE TABLE IF NOT EXISTS "DWCD_LOCAL_TIPO_OCORRENCIA" (
	"SK_Local_Tipo_Ocorrencia" INTEGER NOT NULL,
	"CD_Local_Tipo_Ocorrencia" INTEGER NOT NULL UNIQUE,
	"DS_Local_Tipo_Ocorrencia" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Local_Tipo_Ocorrencia")
);

CREATE TABLE IF NOT EXISTS "DWCD_OBITO_PUERPERIO" (
	"SK_Obito_Puerperio" INTEGER NOT NULL,
	"CD_Obito_Puerperio" INTEGER NOT NULL UNIQUE,
	"DS_Obito_Puerperio" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Obito_Puerperio")
);

CREATE TABLE IF NOT EXISTS "DWCD_RACA" (
	"SK_Raca" INTEGER NOT NULL,
	"CD_Raca" INTEGER NOT NULL UNIQUE,
	"DS_Raca" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Raca")
);

CREATE TABLE IF NOT EXISTS "DWCD_SEXO" (
	"SK_Sexo" INTEGER NOT NULL,
	"CD_Sexo" VARCHAR NOT NULL UNIQUE,
	"DS_Sexo" VARCHAR NOT NULL,
	"DT_Carga" TIMESTAMP NOT NULL,
	PRIMARY KEY("SK_Sexo")
);
  """)

with sql.connect('mortalidade.db') as conn:
  cursor = conn.cursor()
  criar_base_de_dados(cursor)

  # --- Carga de Dimensões Estáticas (Usando SUAS funções) ---
  print("Carregando dimensões estáticas...")
  criar_sexo(cursor)
  criar_raca(cursor)
  criar_obito_puerperio(cursor)
  criar_escolaridade(cursor)
  criar_fonte_informacoes(cursor)
  criar_local_ocorrencia(cursor)
  criar_ocorrencia_obito(cursor)
  criar_local_tipo_ocorrencia(cursor)
  criar_metodo_parto(cursor)
  criar_estado_civil(cursor)
  criar_tipo_gravidez(cursor)
  criar_circunstancia_obito(cursor)
  criar_obito_parto(cursor)

  print("\n--- Verificando Arquivos de Dimensão Externa (Fontes Oficiais) ---")

  # --- 1. IBGE Municípios (DTB) ---
  # REMOVIDO CONFORME SOLICITADO

  # --- 2. CBO Ocupação (MTE) ---
  url_cbo = "https://www.gov.br/trabalho-e-emprego/pt-br/assuntos/cbo/servicos/downloads/cbo2022-ocupacao.csv"
  # Se você já tiver o cbo2002-ocupacao.csv, o script o usará.
  if not os.path.exists("cbo2002-ocupacao.csv"):
      arq_cbo = "cbo2022-ocupacao.csv"
      ok_cbo = baixar_arquivo_direto(url_cbo, arq_cbo)
  else:
      arq_cbo = "cbo2002-ocupacao.csv"
      ok_cbo = True
      print(f"✓ Arquivo 'cbo2002-ocupacao.csv' já existe.")


  # --- 3. CID-10 (DATASUS) ---
  # Usando espelho (mirror) funcional, pois o servidor oficial (datasus.gov.br) está instável
  url_cid = "https://raw.githubusercontent.com/datascience-br/cluster-cid/main/data/CID-10-SUBCATEGORIAS.CSV"
  arq_cid_local = "CID-10-SUBCATEGORIAS.CSV"

  ok_cid = baixar_arquivo_direto(url_cid, arq_cid_local)

  # --- Carga de Dimensões Externas ---
  print("\n--- Carregando Dimensões Externas ---")

  # Bloco ok_municipios REMOVIDO

  if ok_cbo:
    criar_ocupacao(cursor, arq_cbo)
  else:
    print(f"ERRO: Não foi possível carregar Ocupações. Arquivo '{arq_cbo}' indisponível.")

  if ok_cid:
    criar_cid(cursor, arq_cid_local)
  else:
    print(f"ERRO: Não foi possível carregar CID. Arquivo '{arq_cid_local}' indisponível.")

  # --- Carga Fato (Apenas 2023) ---
  print("\n--- Iniciando Carga Fato (Mortalidade) ---")

  ano = 2023

  print("---------------------------------------------------------")
  print(f"Iniciando processamento exclusivo do ano {ano}")

  nome_arquivo_local_fato = f"Mortalidade_Geral_{ano}.csv"
  ano_curto = str(ano)[2:]
  url_mortalidade = f"https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SIM/DO{ano_curto}OPEN.csv"

  arquivo_ok = baixar_arquivo_direto(url_mortalidade, nome_arquivo_local_fato)

  if arquivo_ok:
      criar_pessoa_obito(cursor, nome_arquivo_local_fato, ano)
      print(f"Finalizado processamento de {ano}")
  else:
      print(f"FALHA: Não foi possível processar o ano {ano} devido a erro no download ou arquivo indisponível.")

  print("---------------------------------------------------------")
  print("Commit das transações...")
  conn.commit()
  print("Processo de ETL concluído.")

import pandas as pd
import sqlite3 as sql
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os

# --- Configurações ---
ARQUIVO_CSV_BRUTO = "Mortalidade_Geral_2023.csv"
BANCO_DADOS_LIMPO = "mortalidade.db"
ANO_ANALISE = 2023
PARAMETRO_ANO_LIKE = f"%{ANO_ANALISE}" # Usado para o formato DDMMYYYY

print("--- INICIANDO DIAGNÓSTICO DA ETAPA 2 (Corrigido) ---")
print(f"Analisando o ano: {ANO_ANALISE}")

# Verifica se os arquivos necessários existem
if not os.path.exists(ARQUIVO_CSV_BRUTO):
    print(f"ERRO: Arquivo bruto '{ARQUIVO_CSV_BRUTO}' não encontrado.")
    exit()
if not os.path.exists(BANCO_DADOS_LIMPO):
    print(f"ERRO: Banco de dados '{BANCO_DADOS_LIMPO}' não encontrado.")
    print("Por favor, execute o script etl_dw.py primeiro.")
    exit()

# Conecta ao banco de dados limpo
conn = sql.connect(BANCO_DADOS_LIMPO)

# --------------------------------------------------------------------
# ITEM 1: Diagnóstico de Inconsistência de Dados (Ex: SEXO)
# --------------------------------------------------------------------
print("\n[Item 1/4] Gerando diagnóstico de INCONSISTÊNCIA (SEXO)...")

# 1.1 ANTES (Dados Brutos do CSV)
df_bruto_sexo = pd.read_csv(ARQUIVO_CSV_BRUTO, sep=';', usecols=['SEXO'], dtype=str, encoding='ISO-8859-1')
consulta_antes_sexo = df_bruto_sexo['SEXO'].value_counts(dropna=False).reset_index()
consulta_antes_sexo.columns = ['Codigo_Bruto', 'Contagem']

# 1.2 DEPOIS (Dados Limpos do DB)
# CORREÇÃO: Alterado de strftime('%Y', ...) para LIKE '%2023'
consulta_depois_sexo = pd.read_sql_query("""
    SELECT
        T2.DS_Sexo AS Sexo_Padronizado,
        COUNT(T1.SK_Dados_Demograficos) AS Contagem
    FROM DWMV_OBITO AS T1
    JOIN DWCD_DADOS_DEMOGRAFICOS AS T_PESSOA ON T1.SK_Dados_Demograficos = T_PESSOA.SK_Dados_Demograficos
    JOIN DWCD_SEXO AS T2 ON T_PESSOA.SK_Sexo = T2.SK_Sexo
    WHERE T1.DT_Data LIKE ? -- CORREÇÃO AQUI (lê o formato DDMMYYYY)
    GROUP BY T2.DS_Sexo
""", conn, params=(PARAMETRO_ANO_LIKE,)) # Usa o parâmetro '%2023'

# 1.3 Interpretação e Visualização
print("\n--- Interpretação (Item 1: Inconsistência) ---")
print("O script etl_dw.py resolveu a inconsistência dos códigos de SEXO.\n")
print("ANTES (Dados Brutos):")
print(consulta_antes_sexo.to_markdown(index=False))
print("\nDEPOIS (Dados Limpos no DW):")
print(consulta_depois_sexo.to_markdown(index=False))

plt.figure(figsize=(10, 5))
sns.barplot(data=consulta_antes_sexo, x='Codigo_Bruto', y='Contagem', palette='viridis')
plt.title(f'ANTES: Códigos Brutos de SEXO (Ano {ANO_ANALISE})')
plt.xlabel('Código no CSV')
plt.ylabel('Contagem')
plt.savefig("diagnostico_1_sexo_antes.png")
print("Gráfico salvo: diagnostico_1_sexo_antes.png")


# --------------------------------------------------------------------
# ITEM 2: Diagnóstico de Dados Faltantes (Heatmap)
# --------------------------------------------------------------------
print("\n[Item 2/4] Gerando diagnóstico de DADOS FALTANTES (Heatmap)...")

# 2.1 ANTES (Dados Brutos do CSV)
colunas_heatmap = ['RACACOR', 'ESC', 'ESTCIV', 'OCUP', 'LINHAA']
df_bruto_missing = pd.read_csv(ARQUIVO_CSV_BRUTO, sep=';', usecols=colunas_heatmap, encoding='ISO-8859-1')
df_bruto_missing = df_bruto_missing.replace(r'^\s*$', np.nan, regex=True).replace('9', np.nan).replace('99', np.nan)

plt.figure(figsize=(12, 7))
sns.heatmap(df_bruto_missing.isnull(), cbar=False, cmap='viridis', yticklabels=False)
plt.title(f'ANTES: Heatmap de Dados Faltantes (NaN ou Ignorado) - Ano {ANO_ANALISE}')
plt.savefig("diagnostico_2_heatmap_antes.png")
print("Gráfico salvo: diagnostico_2_heatmap_antes.png")


# 2.2 DEPOIS (Dados Limpos do DB)
# CORREÇÃO: Alterado de strftime('%Y', ...) para LIKE '%2023' na subquery
consulta_depois_missing = pd.read_sql_query(f"""
    SELECT
        COUNT(CASE WHEN SK_Raca = -1 THEN 1 END) AS Contagem_Raca_Faltante,
        COUNT(CASE WHEN SK_Escolaridade = -1 THEN 1 END) AS Contagem_Esc_Faltante,
        COUNT(CASE WHEN SK_Estado_Civil = -1 THEN 1 END) AS Contagem_EstCiv_Faltante,
        COUNT(CASE WHEN SK_Ocupacao = -1 THEN 1 END) AS Contagem_Ocup_Faltante
    FROM DWCD_DADOS_DEMOGRAFICOS
    WHERE SK_Dados_Demograficos IN (
        SELECT SK_Dados_Demograficos FROM DWMV_OBITO
        WHERE DT_Data LIKE ? -- CORREÇÃO AQUI
    )
""", conn, params=(PARAMETRO_ANO_LIKE,))

# 2.3 Interpretação
print("\n--- Interpretação (Item 2: Dados Faltantes) ---")
print("O Heatmap (ANTES) mostra os 'buracos' nos dados brutos (linhas amarelas).")
print("O script etl_dw.py mapeou os valores ausentes para a chave 'SK = -1' (Inválido).\n")
print("DEPOIS (Contagem de 'SK = -1' no DW):")
print(consulta_depois_missing.to_markdown(index=False))


# --------------------------------------------------------------------
# ITEM 3: Diagnóstico de Outliers (Ex: IDADE)
# --------------------------------------------------------------------
print("\n[Item 3/4] Gerando diagnóstico de OUTLIERS (IDADE)...")

# 3.1 ANTES (Dados Brutos do CSV)
df_bruto_idade = pd.read_csv(ARQUIVO_CSV_BRUTO, sep=';', usecols=['IDADE'], encoding='ISO-8859-1')
def tratar_idade_bruta(idade_str):
    if pd.isna(idade_str) or not str(idade_str).isdigit():
        return np.nan
    idade = int(idade_str)
    if idade > 900: return idade
    if idade >= 400 and idade <= 599: return idade - 400
    if idade < 100: return idade
    return np.nan
df_bruto_idade['Idade_Tratada'] = df_bruto_idade['IDADE'].apply(tratar_idade_bruta)

plt.figure(figsize=(10, 6))
sns.boxplot(x=df_bruto_idade['Idade_Tratada'])
plt.title(f'ANTES: Box Plot de IDADE (Ano {ANO_ANALISE})')
plt.xlabel('Idade (Valores > 900 são códigos de ignorado)')
plt.savefig("diagnostico_3_boxplot_idade_antes.png")
print("Gráfico salvo: diagnostico_3_boxplot_idade_antes.png")


# 3.2 DEPOIS (Dados Limpos do DB)
# CORREÇÃO: Alterado de strftime('%Y', ...) para LIKE '%2023' na subquery
consulta_depois_idade = pd.read_sql_query(f"""
    SELECT
        MIN(DS_Idade) as Min_Idade_Limpa,
        MAX(DS_Idade) as Max_Idade_Limpa,
        AVG(DS_Idade) as Media_Idade_Limpa
    FROM DWCD_DADOS_DEMOGRAFICOS
    WHERE DS_Idade != -1 -- Exclui os "Inválidos" da análise estatística
    AND SK_Dados_Demograficos IN (
        SELECT SK_Dados_Demograficos FROM DWMV_OBITO
        WHERE DT_Data LIKE ? -- CORREÇÃO AQUI
    )
""", conn, params=(PARAMETRO_ANO_LIKE,))

# 3.3 Interpretação
print("\n--- Interpretação (Item 3: Outliers de Idade) ---")
print("O Box Plot (ANTES) mostra valores extremos (999) que são códigos de 'ignorado'.")
print("O script etl_dw.py limpou isso, mapeando '999' para -1.\n")
print("DEPOIS (Estatísticas da Idade Limpa no DW, excluindo -1):")
print(consulta_depois_idade.to_markdown(index=False))


# --------------------------------------------------------------------
# ITEM 4: Diagnóstico de Padronização (Ex: LINHAA - CID)
# --------------------------------------------------------------------
print("\n[Item 4/4] Gerando diagnóstico de PADRONIZAÇÃO (CID)...")

# 4.1 ANTES (Dados Brutos do CSV)
df_bruto_cid = pd.read_csv(ARQUIVO_CSV_BRUTO, sep=';', usecols=['LINHAA'], dtype=str, encoding='ISO-8859-1')
regex_problema = r'\*|X$'
contagem_problema_cid = df_bruto_cid['LINHAA'].str.contains(regex_problema, na=False, regex=True).sum()

# 4.2 DEPOIS (Dados Limpos do DB)
# Esta consulta não depende do ano, está correta como estava.
consulta_depois_cid = pd.read_sql_query("""
    SELECT COUNT(*) AS Contagem_Sufixo_Invalido_no_DW
    FROM DWCD_CID
    WHERE CD_CID LIKE '%*%' OR CD_CID LIKE '%X'
""", conn)

# 4.3 Interpretação
print("\n--- Interpretação (Item 4: Padronização CID) ---")
print("O script etl_dw.py usa Regex para limpar sufixos inválidos ('*' ou 'X').\n")
print(f"ANTES: Contagem de CIDs com sufixo inválido no CSV: {contagem_problema_cid}")
print("\nDEPOIS (Verificação na Dimensão DWCD_CID):")
print(consulta_depois_cid.to_markdown(index=False))
print("(A contagem DEPOIS ser 0 prova que a limpeza funcionou).")

# --- Finalização ---
conn.close()
print("\n--- DIAGNÓSTICO DA ETAPA 2 CONCLUÍDO ---")